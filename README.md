# ðŸŽ™ï¸ CoreTranscript

**Lokalny system transkrypcji i diaryzacji (rozpoznawania mÃ³wcÃ³w) zoptymalizowany dla Apple Silicon.**

CoreTranscript to narzÄ™dzie Å‚Ä…czÄ…ce siÅ‚Ä™ modelu **Whisper** (w wersji MLX dla macOS) oraz **Pyannote** (do diaryzacji), opakowane w nowoczesnÄ… architekturÄ™ (Clean Architecture). Pozwala na nagrywanie, transkrypcjÄ™ i analizÄ™ spotkaÅ„ w peÅ‚ni lokalnie, bez przesyÅ‚ania danych do chmury.

## ðŸš€ MoÅ¼liwoÅ›ci

* **Transkrypcja (ASR):** BÅ‚yskawiczna zamiana mowy na tekst dziÄ™ki `mlx-whisper`.
* **Diaryzacja:** Rozpoznawanie "kto mÃ³wi i kiedy" dziÄ™ki `pyannote.audio 3.1`.
* **Interfejs UI:** Prosty panel w przeglÄ…darce (Streamlit) do nagrywania, wgrywania plikÃ³w i podglÄ…du czatu.
* **API:** Wystawione endpointy (FastAPI) gotowe do integracji z automatyzacjami (n8n, Make).
* **PrywatnoÅ›Ä‡:** Wszystko dziaÅ‚a na Twoim sprzÄ™cie (Local First).

---

## ðŸ› ï¸ Wymagania

* **System:** macOS (Zalecany procesor Apple Silicon M1/M2/M3 dla akceleracji sprzÄ™towej).
* **Python:** Wersja 3.10 lub 3.11.
* **Konto Hugging Face:** NiezbÄ™dne do pobrania modelu Pyannote (wymaga akceptacji licencji).

### ðŸ”‘ Krok 0: Przygotowanie Tokena HF
Model `pyannote/speaker-diarization-3.1` jest modelem zamkniÄ™tym. Aby go uÅ¼yÄ‡:

1.  Zaloguj siÄ™ na [Hugging Face](https://huggingface.co/).
2.  Zaakceptuj warunki licencji na stronach obu modeli:
    * [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)
    * [pyannote/segmentation-3.0](https://huggingface.co/pyannote/segmentation-3.0)
3.  Wygeneruj token dostÄ™pu (Settings -> Access Tokens) z uprawnieniami **Read**.
4.  Zachowaj token â€“ bÄ™dzie potrzebny w pliku `.env`.

---

## ðŸ“¦ Instalacja

### 1. Klonowanie repozytorium
```bash
git clone [https://github.com/AdiMlodszy/CoreTranscript.git](https://github.com/AdiMlodszy/CoreTranscript.git)
cd CoreTranscript